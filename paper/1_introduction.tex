\startchapter [title={Introduction}]

This section is organized as follows.
We first provide the motivation, and then overview the existent literature on channel estimation.
Particularly, we will summerize present results on DS and OMP, and argue that DS is a viable solution that has been ignored, and then claim our contribution in this article that will be shown in the later sections.

\stopsection

\startsection [title={Motivation of Compressed Channel Sensing}]

Multiple-input multiple-output (MIMO) communication system has been proposed to be the next-generation specification.
With a large number of antennae of both transmitter and receiver sides (hereafter massive MIMO) is therefore expected to improve spectral efficiency.
But MIMO presents new obstacles as well.
The hardware overhead due to large number of antennas increases complexity and power consumption, and new precoders are being invented to take account of this.
It is important to devise a feasible scheme, as the systems themselves are growing more complicated.
Meanwhile, millimeter waves, having smaller wavelength, entails higher frequency bands, and thus wider available bandwith to be available.
In addition, the smaller closer spaced antennae makes it possible to increase the number antennae.
Consequently, this article considers MIMO in the millimeter r\`egime.

The figure of merit of a MIMO system is usually considered to be the channel capacity.
In vague terms, the capacity \m {C} of a MIMO channel \m {\M {H}} at perfect channel state information is well-known to be roughly in the form \m {\log \det \RB {I +\Rm {SNR}}}, but that knowledge is hardly always available.
What makes things more difficult is the case that \m {\M {H}} is determined from not only the noise itself, but also inherent parameter --- such as, in our case, as shall be seen, the angle of departure and arrival.
It is pointed out that the capacity written in explicit dependence of such parameters is a difficult and long-standing problem (Goldsmith et.\ al.\ 2003).
Nevertheless, the perfect-channel-state-information expression of channel capacity is often used regardless of these issues.
Indeed, analysis of precoding algorithm, for example, usually makes use of the sum rate \m {\log \det \RB {I +\Rm {SNR}}}.

Therefore the real-time estimation, \m {\hat {\M {H}}}, of \m {\M {H}} is of paramount importance.
Needless to say, when the \m {\hat {\M {H}}} is imprecise, resulting analysis is also undermined.
With more antennae present, conventional training-based algorithms also increase in complexity and storage.
In real applications, channel may also be fast varying with respect to time, and a high complexity algorithm is surely less than being ideal.
A design of new algorithms that addressed these issues is thus necessary.

\stopsection
\startsection [title={The Dantzig Selector}]

It is a recent developement that the estimation of channels is facilitated by advances of compressed sensing.
A series of paper by Cand\`es and Tao (2006) marks its advent.

To motivate the need, we observe that it is a common situation in statsitical applications that the number of model parameters \m {N_p \in \MB {N}} is much larger than the number of measurements \m {N_m \in \MB {N}}, namely,
\DispN {
\NC N_p \gg N_m \NR
}
In such case of insufficient measurements, possibly even with corruption of noise, do we have the knowledge of all \m {N_p} parameters?
Of course, more assumption must be made to make the question meaningful.
Any two vectors of parameters differing an element in the null space of the sensing matrix will produce the same measurement.

Cand\`es and Tao showed frst that that in the noiseless case (``Decoding by Linear Programming'', 2006), it is possible to recover the sparse signal, under a \m {\ell_1} minimization program.
The work reveals the phenomenon that few observations of the signal in question may be sufficient for us to resonstruct the signal when it is sparse in a certain sense.

Later they established a stronger result that (``The Dantzig Selector'', 2007), with another \m {\ell_1} minimization program they named The Dantzig Selector (hencefore DS), they can recover the noisy case too.
Such recovery of signals is possible, if we make a few carefully constructed, and seemingly random measurements.
Ever since, it becomes feasible that a camera equipped with few sensors may obtain high quality images, greatly reducing the subsequent cost.
In addition, they derived a probability bound of mean suqare error, showing the probability of successful recovery is overwhelming.

From the realistic perspective, the formulation as an \m {\ell_1} minimization problem, which is convex, made techniques from convex optimization usable.
Indeed, relevent code has been put on the web for the reader to access and verify (Cand\`es \& Romberg 2005).
In this article we focus on DS, and we introduce several notions before we describe their work.

In this section, consider \m {\V {x} \in \MB {K} ^{N_p}} and \m {\V {\Phi} \in \MB {K} ^{N_m \D  N_p}}.
Set \m {\MC {T} \RB {N_p} =\CB {0, \dots, N_p-1}} for short.
For \m {\MC {A} \subseteq \MC {T} \SB {N_p}}, denote
\DispN {
\NC \V {x}  \DB {\MC {A}}
=\NC \sum _{i \in \MC {A}} \V {v} \V {u} _{i} \NR
\NC \M {\Phi}  \DB {\MC {A}}
=\NC \sum _{i \in \MC {A}} \M {\Phi} \DB {:,i} \NR
}
That is, respectfully, the components of \m {\V {x}}, and the columns of \m {\M {A}}, that have indices in \m {\MC {A}}.

We say \m {\V {x}} is \m {s}-sparse, if only at most \m {s} components of \m {x} is nonzero.
Formally,
\Result
{Definition}
{
\m {\V {x}} is called \m {s}-sparse, if there is some \m {\MC {A} \subseteq \MC {T} \SB {N_p}} such that
\DispN {
\NC \V {x} \DB {\MC {A}}
=\NC \V {x} \NR
}
with
\DispN { 
\NC \# \MC {A} \leq s. \NR
}
}

\Result
{Definition: Restricted Isometry Property}
{
For fixed \m {s =0, \dots N_p -1}, we say that \m {\M {\Phi}} satisfies the restricted isometry property (RIP) of sparsity \m {s} with respect to \m {0 \leq \d_s \leq 1}, if, for all \m {s}-sparse \m {\V {x}},
\DispN {
\NC \RB {1-\d_s} \VNm {\V {x}}^2
\leq \NC \VNm {\M {\Phi} \V {x}} _2^2 \NR
\NC \leq \NC \RB {1+\d_s} \VNm {\V {x}} _2^2 \NR
}
}
That is, \m {\Phi} is ``almost unitary'' up to ``relative error'' \m {\d_s}.

Now, consider a linear transformation with noise corruption,

\DispN {
\NC \V {y}
=\NC \M {\Phi} \V {x} + \V {z} \NR
}

where (w.l.o.g.) \m {\V {z}} is an i.i.d.\ normalized Gaussian vector.
How can we hope to estimate \m {\V {x}} when, in addition to insufficient observations, there are too few observations?

\Result
{Algorithm: Dantzig Selector}
{
\startitemize[n]
\item Input \m {\M {\Phi} \in \MB {R} ^{N_m \D N_p}} and \m {\V {y} \in \MB {R} ^{N_m}}.
\item Calculate
\DispN {
\NC \Hat {\V {h}}
\LA \NC \startcases
\NC \Min {\V {h}'} \MC \VNm {\V {h}'} _1 \NR
\NC \Rm {subject} \; \Rm {to} \Q \MC \VNm {\M {\Phi}^\Adj \RB {\M {\Phi} \V {h}' -\V {y}}} _\infty \leq \g \NR
\stopcases \NR
}
\item Output \m {\Hat {\V {h}}}.
}

They was able to show that, with Algorithm (), the mean square error is bounded with overwhelming probability.
And it can be shown that this \m {\ell_1}-minimization problem with \m {\ell_\infty}-constraint may be recast as a linear program (LP), lending convex programming technique applicable.
Note that they confined their discussion for real vectors.

The constant \m {\d} in the proof of DS is significant.
Indeed, we may observe that in theorem (), the bound is not tightest when \m {\d=0}, i.e., that \m {\Phi} is fully unitary, rendering the RIP an important role.
Here, it is not clear at first what matrices serves as the RIP condition.

But later, Baraniuk (2008) have found there is a particularly convenient sufficient condition to verify RIP.

We have summarised results in compressed sensing, and we now relate the matter to the communication scenario.
Recall that the overhead of channel estimation has been a concern in the millimeter wave MIMO setting.
Meanwhile, physical evidences suggest that millimeter wave channels can be said to be sparse in the frequency domain in a certain senses.
Some scholars thus has applied compressive sensing techniques to the problem.

One of the first papers, Bajwa et.\ al.\ (2010) argues the \m {\ell_0}-norm of the channel matrix may be bounded by a constant, and in such settings the Dantzig Selector may be applied.
What they explored was the estimation of single-antenna channel response with respect to time.
Another paper by the same group of scholars (Bajwa et.\ al.\ 2008) shows that \m {X} is RIP for overwhelming probability, providing the ground for the former paper.

To explain the idea, consider a linear time-invariant channel that \m {y\SB {t} =\RB {x \star h} \SB {t} + z\SB {t}}, where \m {h\SB {t}} is the channel's impulse response, \m {y\SB {t}} is the output, and, for each time index, \m {x\SB {t}} is i.i.d.\ Rademacher, and \m {z\SB {t}} is i.i.d.\ Gaussian.
Simply assuming \m {h} is sparse, and let the convolution with \m {x} be expressed by a matrix \m {X}, \m {X} is a Toeplitz matrix, so that \m {y =X h +z}.
Then Bajwa et.\ al.\ was able to show that, \m {X} is RIP of overwhelmingly probability, and DS is ready to be applied, with some nice bounds on its performance drawing from Cand\`es and Tao's theorems.

\stopsection
\startsection [title={Orthogonal Matching Pursuit}]

Around that time, Tropp and Gilbert (2007b) points out if we apply a greedy algorithm called Orthogonal Matching Pursuit (OMP), that an i.i.d.\ random matrix being generated the similar way as Baraniuk (2008) suggested, may perform sufficiently well, even recover the original signal in an overwhemingly probability too.

Same as before, consider an \m {s}-sparse \m {\V {x}}, with \m {N_p \gg N_s}.
For the noiseless, real-number case,
\DispN {
\NC \V {y}
=\NC \M {\Phi} \V {x}, \NR
}
We pick up the columns of \m {\M {\Phi}} greedily, hoping to correspond to the nonzero components of \m {\V {x}}, and thus recovering the original signal.

\Result
{Algorithm: Orthogonal Matching Pursuit}
{
\startitemize[n]
\item Input \m {\M {\Phi} \in \MB {R} ^{N_m, N_p}} and \m {\V {y} \in \MB {R} ^{N_m}}, \m {\eta >0}.
\item Initialize
\DispN {
\NC \V {r}
\LA \NC \V {y} \NR
\NC S
\LA \NC \varnothing \NR
}
\item Start the loop with counter \m {i \LA 1}.
\item Find
\DispN {
\NC c
\LA \NC \underset {i =0, \dots, N_p-1} {\Rm {argmax}}
\Nm {\M {\Phi} \DB {:,i} \V {r}} \NR
}
and insert \m {S \LA S \cup {i}}.
\item Compute
\DispN {
\NC \M {\Phi} ^\ddagger
\LA \NC \RB {\M {\Phi} \DB {S} ^\Adj \M {\Phi} \DB {S}} ^{-1} \M {\Phi} \DB {S} ^\Adj \NR
\NC \V {r}
\LA \NC \V {y} -\M {\Phi} \DB {S} ^\Adj \M {\Phi} ^\ddagger \V {y} \NR
}
\item Break if
\DispN {
\NC \VNm {\V {r}} _2
<\NC \eta \NR
}
where \m {\VNm {\M {\Phi} ^\ddagger} _1} denotes the operator norm.
\item Output 
\DispN {
\NC \Hat {\V {g}}
\LA \NC \M {\Phi} ^\ddagger \V {y} \NR
}
\stopitemize
}
Here \m {\V {r}} can be thought of as the estimated noise, and \m {S} the estimated position where \m {h} is nonzero (where we have slightly abused the usage of double brackets).

From Tropp and Gilbert (2007a), the probability OMP recovers \m {h} completely is overwhelming.

It is interesting to note that, ever since, the channel sensing scholars have applied OMP in favor of DS, due the simplicity of former's implementation, making OMP perhaps the most widely used channel estimation technique.

For our purposes, let \m {\M {F}} be the precoder and \m {\M {W}} the combiner, and \m {\M {H}} the channel, and consider the noiseless case.
Let signal \m {\V {x}} be sent, and \m {\V {y}} be receiverd, that is

\DispN {
\NC \V {y}
=\NC \M {W} \M {H} \M {F} \V {x} \NR
}

\Result
{Definition.}
{
Define \m {\Rm {vec} \SB {\M {A}} \in \MB {K} ^{N_1, N_2}} to be the vectorization of \m {\M {A} \in \MB {K} ^{N_1 \D  N_2}}.
Formally,
\DispN {
\NC \RB {\Rm {vec} \SB {\M {A}}} \DB {m_1}
=\NC \M {A} \DB {m_1\; \Rm {Mod}\; N_1, \Fl { m_1/N_1 }} \NR
}
The bijectivity is obvious, and we define \m {\Rm {vec} ^{-1}} so that
\DispN {
\NC \Rm {vec} ^{-1} \SB {\Rm {vec} \SB {x}}
=\NC x \NR
}
}

\Result
{Definition.}
{
For \m {\M {A} \in \MB {K} ^{N_1 \D  N_2}} and \m {\M {B} \in \MB {K} ^{N_3 \D N_4}}, define the Kronecker product \m {\M {A} \otimes \M {B} \in \MB {K} ^{N_1 N_3 \D N_2 N_4}} by
\DispN {
\NC \NC \RB {\M {A} \otimes \M {B}} \DB {m_1, m_2} \NR
\NC =\NC \M {A} \DB {\Fl { m_1/N_3 }, \Fl { m_2/N_4 }}
\M {B} \DB {m_1\; \Rm {Mod}\; N_3, m_2\; \Rm {Mod}\; N_4} \NR
}
}

With (), scholars often exploit the relation
\Result
{Lemma.}
{
Suppose \m {\M {A} \in \MB {K} ^{N_1 \D  N_2}, \M {X} \in \MB {K} ^{N_2 \D N_3}, \M {B} \in \MB {K} ^{N_3 \D N_4}},
Then
\DispN {
\NC \Rm {vec} \SB {\M {A}\M {X}\M {B}}
= \NC \RB {\M {B}^\Tr \otimes \M {A}} \Rm {vec} \SB {\M {X}} \NR
}
}

To show this, we shall verify that arbitrary components of lhs and rhs agree.
On one hand,
\DispN {
\NC \NC \RB {\Rm {vec} \SB {\M {A}\M {X}\M {B}}} \DB {m_1} \NR
\NC = \NC \RB {\M {A}\M {X}\M {B}} \DB {m_1\; \Rm {Mod}\; N_1, \Fl { m_1/N_1 }} \NR
\NC = \NC \sum _{n_2 =0} ^{N_2 -1} \sum _{n_3 =0} ^{N_3 -1}
\M {A} \DB {m_1\; \Rm {Mod}\; N_1, n_2} \M {X} \DB {n_2, n_3} \M {B} \DB {n_3, \Fl { m_1/N_1 }} \NR
}
On the other hand,
\DispN {
\NC \NC \RB {\RB {\M {B}^\Tr \otimes \M {A}} \Rm {vec} \SB {\M {X}}} \DB {m_1} \NR
\NC = \NC \sum _{m_2 =0} ^{N_2 N_3 -1} \RB {\M {B}^\Tr \otimes \M {A}} \DB {m_1, m_2} \Rm {vec} \SB {\M {X}} \DB {m_2} \NR
\NC = \NC \sum _{m_2 =0} ^{N_2 N_3 -1} \RB {\M {B}^\Tr} \DB {\Fl { m_1/N_1 }, \Fl { m_2/N_2 }}
\M {A} \DB {m_1\; \Rm {Mod}\; N_1, m_2\; \Rm {Mod}\; N_2} \Rm {vec} \SB {\M {X}} \DB {m_2} \NR 
\NC = \NC
\sum _{m_2 =0} ^{N_2 N_3 -1}
\M {B} \DB {\Fl { m_2/N_2 }, \Fl { m_1/N_1 }}
\M {A} \DB {m_1\; \Rm {Mod}\; N_1, m_2\; \Rm {Mod}\; N_2} \NR
\NC \NC \SixQ
\M {X} \DB {m_2\; \Rm {Mod}\; N_2, \Fl { m_2/N_2 }}
\NR
}

In () and (), the row indices of \m {\M {A}} and \m {\M {B}} already agree.
The key observation is that when \m {n_2} runs through \m {0, \dots, N_2-1} and \m {n_3} runs through \m {0, \dots, N_3-1}, it follows \m {n_2 n_3} runs through \m {0, \dots, N_2 N_3-1}.
We see two expressions are exactly the same, and we are done.

The matrix consisting of the collection of possible response according to available paths --- called the dictionary --- plays the role of the sensing matrix of OMP.
The combiner at the receiver end corresponds to the step where we map the data from high to low dimension.

\stopsection

\startsection [title={Further Development}]

The literature on Compressive Channel Sensing has since been vast, and we need not and cannot go through all of them here.
Rather, we analyze the respective contribution and weakness on some of the recent seminal papers.

Rao and Lau (2014) considers a distributed algorithm for a MU-MIMO and proposes a modified joint OMP algorithm, with the assumption on the sparsity of the channel and that channels seen by various users shall share the same positions of nonzero components.

Alkhateeb et.\ al.\ (2014) suggests an adaptive OMP algorithm, using a (beam) code book with quantized AoA and AoD.

Alkhateeb, Leus, and Heath Jr.\ (2015) poses the interesting trade-off of number of OMP measurement and accuracy in an application of OMP.
They work simplified all-phase-shifter combiner model, where every receiver antenna may only multiply the signal by a constant, and the channel model is assumed to take value on a quantized, non-uniform set of angles.
Their work mainly focuses on numerical simulation, rather than mathematical proof.

Since the notice of hybrid beamforming, scholars have also applied the same idea to hybrid systems.
Lee, Gil, and Lee (2016) considers a hybrid beamforming system, where the composition of the precoders and combineres play the role of sensing matrix.
The beambook phase is quantized, which may have been a source of error, and they have specifed a particular grid set of angles and argues the superiority.
One of their simulations experiments utilizes DFT and permutated DFT matrix, instead of as originally suggested by Tropp and Gilbert (2007).

Meanwhile, the improvement of OMP bound is also going on.
Cai, Wang, and Xu (2010), making assumptions on MIP matrices, give new bound on OMP, and, in addition, Cai and Wang (2011) replicates the same for analysis for DS, among other convex algorithms.
Indeed, MIP deals with correlation of columns of the sensing matrix, rather than the almost-unitarity, making the condition easier to verify.

Ben-Haim et.\ al.\ (2010) follow up their work and refine their bounds, also considering MIP conditions.
They conclude that OMP is better for low-SNR scenario, and DS is better for high-SNR.
Still, since the setting of OMP and DS is rather different, it remains unclear which of is better.

Alkhateeb, Leus, and Heath (2015), being a recent paper, cites Ben-Haim et.\ al.\ (2010) as the main foundation for OMP perfomance bound.

Gao et.\ al.\ (2015) discusses the jointly reconstruction of several high-dimensional sparse signals having the same positions of nonzero components, using different measurement matrices in a modified basis pursuit problem.

We remark several observation on past literature, that has been, to the best of our knowledge, lacking or less than ideal.

\startitemize
\item Previous work favors OMP rather than DS, let alone other sparse algorithm.
\item Previous work simply assumes the bound of the norm of the channel matrix.
\item The condition that the sensing matrix should be elementwise i.i.d.\ Normal (required by Tropp and Gilvert 2007) seems to be more restrictive than RIP (required by Cand\`es and Tao 2007).
\item The quantization of angle in generating may be a problem, and that is difficult to analyze in OMP's setting
\item No bounds is derived that explicitly depends on the sparsity of the channel parameters as, say, number of channel paths and array response.
\stopitemize

\startsection [title={Our Contribution}]

We consider a system model where both digital and analog beamformer are i.i.d.\ random matrix combiner that serve readily as the sensing matrix satisfying the RIP property.
We apply a convex program analogous of DS in order to directly estimate the channel under hypothesis of uniform linear array response.
Moreover, inspired by the lines of proof of Cand\`es and Tao (2006), we give a bound that indicates our method is to be successful for overwhelming probability.

Our contribution includes:

\startitemize
\item As a {\it prima face} difference, we use a modified DS rather than OMP, done on the beamspace rather than the spatial domain, and involving complex numbers rather than real numbers.
\item Moreover, an explicit bound has been shown to provide realistic guide for engineering, where the sparsity of the virtual channel matrix, rather than just assumed, is written out as a function of the number of paths of the channel.
\item Accordingly, the concern of quantization error of the virtual channel's phase angle (which is inevitable when designing the OMP beambook) has already been considered in the proof of our main bound.
\item We derive explicitly the SOCP problem and afterwards its dual problem, and wrote a proof-of-concept but efficient code.
\stopitemize

\stopsection

\stopchapter

