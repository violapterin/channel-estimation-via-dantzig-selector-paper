\Frame {The Need of a Modified Proof}
{
\I \Emph {Q1}: Dantzig Selector works for \Emph {sparse} vectors, but while \m {\M {H}} is sparse in the angular domain, is it sparse by itself?

\I \Emph{Q2}: Dantzig Selector requires the measurement matrix to observe restricted isometry property (more below), but is it true for \m {\M {P}}, and for what \Emph {design} of \m {\M {F}_B, \M {F}_R, \M {W}_B, \M {W}_R}?

\I \Emph{Q3}: Cand\`es and Tao established the case for real matrices, but does \Emph {complex} case apply?

\I \Emph{Q4}: Cand\`es and Tao showed the Big-O error bound in terms of (in our notation) \m {N_H}, but does, for practical values, the algorithm converges for \Emph {high probability}?
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Restricted Isometry Property}
{
\I \m {\V {g}} is called \Emph {\m {s}-sparse}, if only \m {s} of its components are nonzero.

\I We say that \m {\M{P}} satisfies the \Emph {restricted isometry property} (RIP) of sparsity \m {s} with respect to \m {0 < \d_s < 1}, if, for all \m {s}-sparse \m {\V {g}},
\Disp {
\NC \RB {1-\d_s} \VNm {\V {g}}^2
\leq \NC \VNm {\M{P} \V {g}} _2^2
\leq \RB {1+\d_s} \VNm {\V {g}} _2^2
}

\I Interpretation: \m {\M{P}} is \Emph {almost unitary} up to relative error \m {\d_s}.

\I Set shorthand, for any unit vector \m {\V{u}},
\Disp {
\NC \rho := \NC \VNm {\M{P} \V{u}}_2^2 \NR
}
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Proof Strategy}
{
\I Show that \m {\V{g}} is almost sparse

\I Find \m {\MB {E} \SB {\rho}} and \m {\MB {E} \SB {\rho^2}}, and bound \m {\MB {E} \SB {\rho ^k}} for \m {k=3,4,5,\dots}.

\I Bound the probability that \m {\Nm {\VNm {\M{P} \V{u}} _2 ^2 -\VNm {\V{u}} _2 ^2} \geq \e \VNm {\V{u}} _2 ^2}.

\I Establish that \m {\M{P}} satisfies RIP for what probability

\I Take into consideration how \m {\V{g}} is not exactly sparse
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {\m {\V{g}} is Almost Sparse}
{
\I Call the vector of largest-magnitude \m {N_H L} positions of \m {\V{g}} to be \m {\V{g}_A}, and remaining positions of \m {\V{g}} to be \m {\V{g}_K}, so that \m {\V{g}_A +\V{g}_K =\V{g}}

\I We can show that 
\Disp {
\NC \V{g}_K
\leq R
:=\m {\F{1}{3 \R{N_H}}} \NR
}

\I \m {R \to 0} as \m {N_H \to \infty}
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Concentration Inequality}
{

\I According to Lemma 5.1 in Baraniuk et.\ al.\ (2008), it has been established that, if the \Emph {concentration inequality} holds that
\Disp{
\NC \MB{P}
\SB {
  \Nm {\VNm {\M{P} \V{u}} _2 ^2 -\VNm {\V{u}} _2 ^2}
  \geq \F {\d_s} {2} \VNm {\V{u}} _2 ^2
}
\leq \NC B \RB {\d_s, N_Y} \NR
}
\I then, supppose the probability that RIP holds for \m {\M{P}} is \m {p},
\Disp{
\NC 1 -p
\leq \NC \RB {\F {12 e N_H} {s \d_s}} ^s B \RB {\d_s, N_Y} \NR
}

\I Our task is reduced into establishment of the inequality!
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Design of Beamformers}
{
\I Considering \Emph {Q2}: If each entry of \m {\M {P}} is i.i.d., then it's likely that, by whatever variation of Central Limit Theorem,
\Disp {
\NC \MB {E} \SB {\rho ^{k}}
\approx \NC 1
\quad \Ss {in distribution} \NR
}

\I Unfortunately, they are \Emph {not i.i.d.}!
\m {\Rightarrow} Need closer scrutiny.

\I Try to set each entry of \m {\M{F}_B} (resp.\ \m {\M{W}_B}) to be i.i.d.\ Standard Complex Normal, multiplied by a design constant \m {\l_B >0} (so that the magnitude follows Rayleigh distribution).

\I And let each entry of \m {\M{F}_R} (resp.\ \m {\M{W}_B}) be uniformly distributed on the unit circle on the complex plane, multiplied by a design constant \m {\l_B >0}.
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Chernoff Inequality}
{
\I Imitating the Chernoff Inequality argument in classical probability, we have, for any \m {s >0} so that, supposedly, both sides \m {< \infty},
\Disp {
\NC p
= \NC \MB{P} \SB {\rho \geq \RB {1 +\e} \MB{E} \SB {\rho}} \NR
\NC =\NC \MB{P} \SB {\Ss {e} ^{s \rho} \geq \Ss {e} ^{s \RB {1 +\e}}} \NR
\NC \leq \NC \Ss {e} ^{-s \RB {1 +\e}} \MB{E} \SB {\Ss {e} ^{s \rho}} \NR
}

\I Assuming the convergence of power series for a moment,
\Disp {
\NC \MB{E} \SB {\Ss {e} ^{s \rho}}
=\NC \sum_{k=0}^\infty \F{s ^k} {k!} \MB{E} \SB {\rho ^k} \NR
}

\I But what are the \Emph {moments} of \m {\rho}?
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Finding the First Moment}
{
\I It is easy show that
\Disp {
\NC \MB{E} \SB {\rho}
= \NC N_Y^2 N_R^2 \l_B^4 \l_R^4 \D \VNm {\V{u}} _2 ^2 \NR
}

\I This motivates
\Disp {
\NC \l_B
=\NC \F {1} {\R {N_Y}},
\l_R
=\F {1} {\R {N_R}} \NR
}

\I So that
\Disp {
\NC \MB{E} \SB {\rho}
=\NC 1
}
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Finding the Second Moment}
{
\I We can show that, after tedius calculation,
\Disp {
\NC \MB{E} \SB {\rho ^2}
\leq \NC N_Y^4 N_R^4 \l_B^8 \l_R^8 \RB {1 +N_Y^{-2}} \D \VNm {\V{u}} _2 ^4 \NR
\NC = \NC \RB {1 +N_Y^{-2}} \NR
}
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Bounding Higher Moments}
{
\I We can show that, after a lot applications of various inequalities,
\Disp {
\NC \MB{E} \SB {\rho ^k}
\leq \NC N_Y^{2k} N_R^{2k} \l_B^{4k} \l_R^{4k}
\D \G \SB {k +1}^2
\D \VNm {\V{u}} _2 ^k \NR
\NC = \NC \G \SB {k +1}^2 \NR
}
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Try to Substite the Moments of \m {\rho}...}
{
\I Plugging into the Chernoff Inequality we have
\Disp {
\NC \log p
\leq \NC \Min {s >0} \Bigg [
  -\RB {1 +\F{1}{2} \e -\F{1}{8} \e^2} s \NR
  \NC \NC \FourQ +\log \RB{
    1
    +s \MB{E} \SB {\rho}
    +\F{s ^2} {2} \MB{E} \SB {\rho^2}
    +\dots
  }
\Bigg ] \NR
}

\I We want the exponent to go small, and it looks promising.

\I But the remainder term of MGF, \m {\MB{E} \SB {\Ss {e} ^{s \rho}}}, seems to \Emph {diverge}!
\Disp {
\NC \sum_{k=3}^\infty \F{s ^k} {k!} \MB{E} \SB {\rho ^k}
\leq \NC \sum_{k=3}^\infty \F{s ^k} {k!} \G \SB {k +1}^2
= \sum_{k=3}^\infty k! \D s ^k
\to \infty \NR
}
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Try Again for \m {\R {\rho}}...}
{
\I Take square roots on both sides so that \m {\sum_{k=3}^\infty s ^k} is finite for \m {s <1}.
\Disp {
\NC p
= \NC \MB{P} \SB {\rho \geq \RB {1 +\e} \MB{E} \SB {\rho}} \NR
\NC =\NC \MB{P} \SB {\Ss {e} ^{s \R {\rho}} \geq \Ss {e} ^{s \R {1 +\e}}} \NR
\NC \leq \NC \Ss {e} ^{-s \R {1 +\e}} \MB{E} \SB {\Ss {e} ^{s \R {\rho}}} \NR
}

\I The \m {1/2} and \m {3/2} moments can be bounded by Cauchy Inequality:
\Disp{
\NC \F{1}{\R{1+N_Y^{-2}}}
\leq \NC \MB{E} \SB {\R{\rho}}
\leq 1, \NR
\NC 1
\leq \NC \MB{E} \SB {\rho ^{3/2}}
\leq \R{1+N_Y^{-2}}, \NR
}
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Confirming the Concentration Ineq.}
{
\I Thus, Minimizing for \m {s} we have, for any \m {\e >0},
\Disp {
\NC \NC \log p \NR
%
\NC =\NC \Min {s >0} \Bigg [
  -\RB {1 +\F{1}{2} \e -\F{1}{8} \e^2} s
  +\MB{E} \SB {\R{\rho}} s
  +\F{1}{2} \RB {\MB{E} \SB {\rho} -\MB{E} \SB {\R {\rho}}^2} s^2 \NR
  \NC \NC \FourQ +\F{1}{6} \RB {-3 \MB{E} \SB {\R {\rho}} \MB{E} \SB {\rho} +2\MB{E} \SB {\R{\rho}} ^3 +\MB{E} \SB {\rho ^{3/2}}} s^3
  +\dots
\Bigg ] \NR
%
\NC =\NC \Min {s >0} \SB{
  -\F{1}{2} \e s
  +\F{1}{2} N_Y^{-2} \RB {1 -N_Y^{-2}} s^2
  +N_Y^{-2} \RB {\F{1}{3} -\F{5}{24} N_Y^{-2}} s^3
} \NR
%
\NC =\NC -\F{\e^2 N_Y^2} {8} \NR
}
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Confirming the Concentration}
{
\I The lower tail can be proved in the same way as upper tail.

\I Conbining we have
\Disp{
\NC \MB{P}
\SB {
  \Nm {\VNm {\M{P} \V{u}} _2 ^2 -\VNm {\V{u}} _2 ^2}
  \geq \e \VNm {\V{u}} _2 ^2
}
\leq \NC 2\exp \SB {-\F{N_Y^2}{8} \e^2} \NR
}
}
% % % % % % % % % % % % % % % % % % % % % % % % % %
\Frame {Expected Error of DS}
{
\I In answer of \Emph {Q3}, It can be checked that the generalization from real to complex does not affect the argument, but only loosen the bound by a multiple.

\I In conclusion, and also in answer of \Emph {Q4}, the bound
\Disp {
\NC \VNm {\V {d}} _2
\leq \NC 4 \R{2} \D \R{L N_H \log N_H} \NR
}

\I holds for probability \m {p}, 
\Disp {
\NC p
\geq \NC 1 -2 \D 6^{N_H L} \D \exp \SB {-\F{N_Y^2} {32}} \NR
}

\I Note that \m {p \to 1} as \m {N_Y \to \infty} exponentially.
}
