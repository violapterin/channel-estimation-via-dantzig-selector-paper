\startsection [title={Expected Error Analysis for Dantzig Selector}]
\startsubsection [title={Generalizing Technical Lemmata for Complex Case}]

Let \m {\hat {\V {g}}} be the Dantzig Selector.
For concreteness, we set
\Disp {
\NC \g 
= \NC \R {2 \log N_h} \NR[+]
}

Other values are of course possible, but this is enough to illustrate our purpose.
Also set for short
\Disp {
\NC \V {d} 
= \NC \Hat {\V {g}} -\V {g} \NR[+]
}

The rest follows \quotation {The Dantzig Selector} very closely.
The generalization to complex vector is necessary in our setting.
We spell out the proof when such generalization is nontrivial.

\Result
{Lemma}
{
Let \m {\V {g}} and \m {\V {d}} be defined as above.
Then
\Disp {
\NC \VNm {\V {d} _{\MC {K}}} _1
\leq \NC \VNm {\V {d} _{\MC {A}}} _1 +2\VNm {\V {g} _{\MC {K}}} _1 \NR
}
}

To show this, observe that with triangle inequality applied respectively on \m {\MC {A}} and \m {\MC {K}},
\Disp {
\NC \VNm {\V {g}} _1
-\VNm {\V {d} _{\MC {A}}} _1
+\VNm {\V {d} _{\MC {K}}} _1
-\VNm {\V {g} _{\MC {K}}} _1
\leq \NC \VNm {\V {g} +\V {d}} _1 \NR
}
In the first line, we recall \m {\V {g} =\V {g} _{\MC {A}}}.
On the other hand, by construction that \m {\hat {g}} minimizes the \m {\ell_1}-norm,
\Disp {
\NC \VNm {\V {g} +\V {d}} _1
=\NC \VNm {\hat {\V {g}}} _1 \NR
\NC \leq \NC \VNm {\V {g}} _1 \NR
}
The result follows by combining.

\Result
{Lemma}
{
\Disp {
\NC \MB {E} \SB {\Nm {\IP {\V {z} \SB {\o_z}, \M {P} \DB {:, n_h}}}}
\leq \NC  2 \R {\log N_h} \NR
\NC n_h 
=\NC 1, \ldots, N_h. \NR
}
with probability \m {\geq 1 -N_h^{-1}}.
}

Indeed, recall the fact that \m {\M {P} \DB {:, n_g}} has unity \m {\ell_2}-norm, and on the randomness of \m {\V {z}}.

Recall the following bound for \m {Q} function
\Disp {
\NC Q\SB {x}
\leq \NC \F {1}{2} \Ss {e}^{-x^2/2} \NR
}
Particularly, for \m {x =\R {2 \log N_h}},
\Disp {
\NC Q\SB {\R {2 \log N_h}}
=\NC \F {1}{N_h}. \NR
}

\Result
{Lemma}
{
With the condition that \m {\M {P}} satisfies RIP for \m {\d_S \SB {\M{P}}},
\Disp {
\NC \VNm {\M {P}^\Adj \M {P} \V {d}} _\infty
\leq \NC  4 \R {\log N_h} \NR
}
with probability \m {\geq 1 -N_h^{-1}}.
}

To show this, by definition
\Disp {
\NC \IP {\V {z} -\RB {\V {y} -\M {P} \hat {\V {g}}}, \M {P} \DB {:,n_y}}
= \NC \IP {\M {P} \hat {\V {g}} -\M {P} \V {g}, \M {P} \DB {:,n_y}} \NR
\NC = \NC \IP {\M {P} \V {d}, \M {P} \DB {:,n_y}} \NR
}
By construction
\Disp {
\NC \VNm {\M {P} \DB {:,n_y}^\Adj \RB {\V {y} -\M {P} \hat {\V {g}}}} _\infty
\leq \NC \VNm {\M {P}^\Adj \RB {\V {y} -\M {P} \hat {\V {g}}}} _\infty \NR
\NC \leq \NC 2\R {\log N_h} \NR
}
By triangle inequality, together with Lemma (), we have
\Disp {
\NC \VNm {\M {P} \DB {:,n_y}^\Adj \M {P} \V {d}} _\infty
\leq \NC \VNm {\IP {\V {z}, \M {P} \DB {:,n_y}}} _\infty
+\IP {\V {y} -\M {P} \hat {\V {g}}, \M {P} \DB {:,n_y}} \NR
\NC \leq \NC 2 \R {\log N_h} +2 \R {\log N_h} \NR
}
which implies
\Disp {
\NC \VNm {\M {P}^\Adj \M {P} \V {d}} _\infty
\leq \NC 4 \R {\log N_h}. \NR
}

From \quotation {Dantzig Selector} Lemma 1, first equation, we have the result as below.
The original result is for real vector spaces, but we have checked that the proof is completely valid in complex vector spaces.
The only thing that has to change accordingly is the interpretation of magnitude and the inner product, which are evident.

\Result
{Lemma}
{
With the condition that \m {\M {P}} satisfies RIP for \m {\d_S \SB {\M{P}}},
\Disp {
\NC \VNm {\V {d} _{\MC {AB}}} _2
\leq \NC \F {1}{1-\d_{2S}} \VNm {P _{\MC {A} \MC {B}}^\Tr P d} _2 +\F {\d_{3S}}{\RB {1-\d_{2S}} \R {S}} \VNm {d_{\MC {K}}} _1 \NR
}
}

From \quotation {Dantzig Selector}, Lemma 1, second equation, we have the result as below.
Again, their proof works with complex vector spaces in place of real ones too.

\Result
{Lemma}
{
\Disp {
\NC \VNm {\V {d}} _2^2
\leq \NC \VNm {\V {d} _{\MC {A} \MC {B}}} _2^2 +\F {1}{S} \VNm {\V {d} _{\MC {K}}} _1^2 \NR
}
}

\stopsubsection

\startsubsection [title={Main Result}]

We are going to combine previous lemmata and show the main result.
In accordance with (), set
\Disp{
\NC S
=\NC s^2 L \NR
}

\Result
{Theorem}
{
Let \m {\V {y}}, \m {\M {P}}, \m {\V {g}}, \m {\hat {\V {g}}}, \m {\V {d}} be defined as above.
Then, with \m {S =s^2 L}, as \m {N_H \to \infty},
\Disp {
\NC \VNm {\V {d}} _2
\leq \NC 32 s^2 L \log N_H \NR[+]
}
Under the design condition
\Disp {
\NC \RB {2 N_H}^2
\approx \NC N_Y^3 \NR[+]
}
the bound holds for probability \m {p}, with
\Disp {
\NC 1 -p
\leq \NC 16 \D {12}^S \d_{S}^{-S-2} N_H^2 N_Y^{-3} \NR[+]
}
}

The first quantity we want to bound away is
\Disp {
\NC \VNm {\M {P} _{\MC {A} \MC {B}}^\Tr \M {P} \V {d}} _2
\leq \NC \VNm {\M {P}^\Tr \M {P} \V {d}} _2 \NR
\NC \leq \NC \R {S} \VNm {\M {P}^\Tr \M {P} \V {d}} _\infty \NR
\NC \leq \NC 4 \R {S \log N_h} \NR
}
Thus, by virtue of Lemma (), and approximating \m {1 /(1 -\d_{2S}) =1 +\d_{2S}} and so on,
\Disp {
\NC \VNm {\V {d}_{\MC {A}}} _1
\leq \NC \R {S} \VNm {\V {d}_{\MC {A}}} _2 \NR
\NC \leq \NC \R {S} \VNm {\V {d} _{\MC {AB}}} _2 \NR
\NC \leq \NC \d_{3S} \RB {1+\d_{2S}} \VNm {\V {d} _{\MC {K}}} _1
+4 \RB {1+\d_{2S}} S \R {\log N_h} \NR
}

Next, we must eliminate \m {\VNm {d _{\MC {A}}} _1} in rhs of Lemma ().
\Disp {
\NC \VNm {\V {d} _{\MC {K}}} _1
\NC \leq \d_{3S} \RB {1+\d_{2S}} \VNm {\V {d} _{\MC {K}}} _1
+4 \RB {1+\d_{2S}} S \R {\log N_h}
+2 \VNm {\V {g} _{\MC {K}}} _1 \NR
}
Arranging and drop second order small terms like \m {\d_{2S} \d_{3S}}, that is,
\Disp {
\NC 1 \ll \NC S \NR
\NC \ll \NC N_h \NR
}
doing this we have
\Disp {
\NC \VNm {\V {d} _{\MC {K}}} _1
\leq \NC 2 \RB {1+\d_{3S}} \VNm {\V {g} _{\MC {K}}} _1
+4 \RB {1+2\d_{3S}} S \R {\log N_h} \NR
}

We are now in a position to bound \m {\VNm {d} _2^2}.
Using Lemma () again, and only keeping to first order, we have
\Disp {
\NC \VNm {\V {d}} _2^2
\leq \NC 16 S \log N_h
+8 \d_{3S} \R {\log N_h} 
+\F {\d_{3S}^2} {S} \VNm {\V {d} _{\MC {K}}} _1 \NR
}
Finally, plug in the bound for \m {\VNm {\V {d} _{\MC {K}}} _1}, the last unknown, and we make use of the almost-sparsity condition of \m {\VNm {\V {d} _{\MC {K}}} _1}.
Again for simplicity, we keep only the first order small terms.
Plug in \m {S =s^2 L} and \m {N_h =N_H^2} we get, finally,
\Disp {
\NC \VNm {\V {d}} _2^2
\leq \NC 32 s^2 L \log N_H
+\F {8 \R {2\pi}} {3} \d_{3S} L \R {\F {\log N_H} {N_H}}
+\F {\pi} {9} \F {L} {s^2 N_H} \NR
}
In particular for asymptotic \m {N_H \gg 1}, keep only the dominating term.
\Disp {
\NC \VNm {\V {d}} _2^2
\leq \NC 32 s^2 L \log N_H \NR
}

The probability that it is true may be bounded by plugging the probability in Lemma () and Lemma ().

\stopsubsection
\stopsection


