% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Reducing the complexity}
{
\I Casting to a linear program

\I A successive estimation of the nonzero components (not used in the final set of figures)

\I Use the basis pursuit denoising form
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Performance Metric}
{
\I Let the \m {\T {\chi}}, the relative 2-norm error, be the performance metric.

\Disp {
\NC \T {\chi}
=\NC \RB {
   \F {\VNm {\V {h} -\Hat {\V {h}}} _2}
   {\VNm {\V {h}}_2}
} _{\Ss {avg}}, \NR
}

\I Also define \m {\chi} by plugging in \m {\V {d}} into \m {\T {\chi}}.
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Error norm (2 stages), \m {N_H=6, N_{B,t}=3, N_{B,t}=2}}
{
\blank [big]
\externalfigure [error-small-wide-two.png] [width=11cm]
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Error norm (2 stages), \m {N_H=6, N_{B,t}=2, N_{B,t}=3}}
{
\blank [big]
\externalfigure [error-small-tall-two.png] [width=11cm]
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Error norm (2 stages), \m {N_H=12, N_{B,t}=6, N_{B,t}=4}}
{
\blank [big]
\externalfigure [error-small-wide-two.png] [width=11cm]
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Error norm (2 stages), \m {N_H=12, N_{B,t}=4, N_{B,t}=6}}
{
\blank [big]
\externalfigure [error-small-tall-two.png] [width=11cm]
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Error norm (2 stages), \m {N_H=18, N_{B,t}=9, N_{B,t}=6}}
{
\blank [big]
\externalfigure [error-small-wide-two.png] [width=11cm]
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Error norm (2 stages), \m {N_H=18, N_{B,t}=6, N_{B,t}=9}}
{
\blank [big]
\externalfigure [error-small-tall-two.png] [width=11cm]
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Discussion}
{
\I DS outperforms other methods in the high noise case

\I DS requires less sampling to recover for given channel instance.

\I The relaxed sparsity may have compromised effectiveness of DS.

\I DS has complexity much higher than OMP, and somewhat higher than Lasso.

\I \m {\T {\chi}} and \m {\chi} differ by some orders of magnitude.
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Complexity}
{
\I Let \m {C} denote big-O estimation of complexity, then we argue in the treatise
\Disp {
\NC C_{\Rm {OMP}} =\NC \mathcal {O} \SB {N_H^2 \log N_B} \NR
\NC C_{\Rm {Lasso}} =\NC \mathcal {O} \SB {N_H^6} \NR
\NC C_{\Rm {DS}} =\NC \mathcal {O} \SB {N_{H}^6} \NR
}

\I Fitting the exponent of runtime statistics roughly agrees these result.

\I In certain conditions it is pointed out Lasso and DS are equivalent.
}


