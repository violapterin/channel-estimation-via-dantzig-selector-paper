\Frame {Modifying the Original Proof}
{
\I \Emph{Q1}: Candès and Tao established the case for real matrices, but does \Emph {complex} case apply?

\I \Emph {Q2}: DS works for \Emph {sparse} vectors, but as \m {\M {H}} is not sparse, does DS work?

\I \Emph{Q3}: DS requires the measurement matrix to have restricted isometry property, but under what \Emph {design} of \m {\M {F}_B, \M {F}_R, \M {W}_B, \M {W}_R}, is it true for \m {\M {P}}?

\I \Emph{Q4}: Candès and Tao showed the Big-\m {\MC {O}} of error norm depends on (in our case) \m {N_H}, but does the algorithm work successfully for \Emph {high probability}?
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Real Valued Representation}
{
\I To save complexity, we represent a complex number by its real- and imarinary-parts.

\I For vectors, substitute
\Disp {
\NC a +b \Ss{i}
\leftrightarrow \NC \startTheMatrix
\NC a \NR
\NC b \NR
\stopTheMatrix \NR
}

\I For matrices, substitute
\Disp {
\NC a +b \Ss{i}
\leftrightarrow \NC \startTheMatrix
\NC a, \NC -b \NR
\NC b, \NC a \NR
\stopTheMatrix \NR
}
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %

\Frame {Observations on Sparsity}
{
\I \m {\M {H}} is not sparse, but \m {\M {K}^\Adj \M {H} \M {K}} is almost sparse.
Call the largest-magnitude \m {S} components of \m {\V{g}} to be \m {\M {g} _{\SB{\MC {A}}}}, and call the remaining vector \m {\M {g} _{\SB{\MC {C}}}}, we still have to bound \m {\VNm {\M {g} _{\SB{\MC {C}}}} _1}.

\I Establish that all four beamformers satisfy RIP, for high probability, thus \m {\m {P}} satisfies RIP too, for high probability.

\I We then establish a modified bound of error norm.
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {\m {\V{g}} is Almost Sparse}
{
\I Suppose for concreteness,
\Disp {
\NC S
= L \log N_H,
\Q \d_S
\leq \F {1} {8} \NR
}

\I We may show that 
\Disp {
\NC \VNm {\M {g} _{\SB{\MC {C}}}} _1
\leq \NC \F {4} {3} \RB {\log N_H}^2 \NR
}

\I holds for probability \m {p}, with
\Disp {
\NC 1 -p
\leq \NC 2 \exp \SB {-\F {9L} {\pi}} \NR
}
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Design of Beamformers}
{
\I I argue in the treatise that \m {\M {F} _R ^\Tr}, \m {\M {F} _B ^\Tr}, \m {\M {W} _R}, and \m {\M {W} _B} all have RIP, then \m {\M {P}} has?

\I Try to set each entry of \m {\m {F}_B} (resp.\ \m {\m {W}_B}) to be i.i.d.\ Complex Standard Normal, up to a design constant

\I And let each entry of \m {\m {F}_R} (resp.\ \m {\m {W}_R}) be uniformly distributed argument and unity magnitude, up to a design constant
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {RIP of Digital Beamformers}
{
\I For \m {0 <\d_s <1}, unit vector \m {\V {u}}, \m {\M {W}_B} (resp.\ \m {\M {F} _B ^\Adj}) satisfies
%
\Disp {
\NC \Nm {\VNm {\M {W} _B \V {u}} _2^2 - 1}
\geq \NC \d_s \NR
}

\I holds for probability \m {p}, with
\Disp {
\NC 1 -p
\leq \NC 2 \Ss {e} ^{-N_Y \R {\d_s} /4} \NR
}
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {RIP of Analog Beamformers}
{
\I Suppose
%
\Disp {
\NC N_R
\geq \NC \F {s} {\d_s^2} \RB {\log s}^2 \log N_H \NR
}
%
\I Then \m {\M {W}_R} (resp.\ \m {\M {F} _R ^\Adj}) has \m {\d_s}-RIP...

\I for probability \m {p}, with
\Disp {
\NC 1 -p
\leq \NC \RB {\F {\d_s} {N_H s}} ^{1/3} \NR
}
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Error Norm of Dantzig Selector}
{
\I The following bound holds for high probability \m {p}:
\Disp {
\NC \VNm {\Hat {\V {g}} - \V {g}} _2
%
\leq \NC 8 \R {L} \R {\log N_H}^3 \NR
}

\I where it hold for \m {p} that...
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Big-\m {O} of Success Probability}
{
\I Denote the four events of failure, subscript respectively for restricted isometry, noise, sparsity,
\Disp {
\NC q = 1-p
\lesssim \NC 2 \RB {q _{\Rm {iso}, B} + q _{\Rm {iso}, R}} +q _{\Rm {no}} +q _{\Rm {sp}} \NR
}

\I If we provide the design values
\Disp {
\NC N_Y
\gtrsim \NC 4 \log N_H, \Q
N_R
\gtrsim 16 L \RB {\log N_H}^2 \NR
}

\I It follows that
\Disp {
\NC q _{\Rm {sp}}
\lesssim \NC q _{\Rm {no}}
\lesssim q _{\Rm {iso}, B}
\eqsim q _{\Rm {iso}, R} \NR
%
\NC q
\lesssim \NC 2 N_H ^{-1/3} \NR
}
}


