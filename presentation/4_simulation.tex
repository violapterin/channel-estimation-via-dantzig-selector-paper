% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Linear Programming}
{
\I DS is equivalent to a linear program, which allows more efficient convex programming methods to be used.

\I Calculate
\Disp {
\NC \Hat {\V {g}}, \Hat {\V {f}}
\LA \NC \startcases
   \NC \Min {\V {g}', \V {f}'}  \MC \IP {\V {1}, \V {f}'} \NR
   \NC \Rm {subject} \; \Rm {to} \MC \V {g}' \leq \V {f}' \NR
   \NC \MC - \V {g}' \leq \V {f}' \NR
   \NC \MC \M {P}^\Adj \M {P} \V {g}' \leq \M {P}^\Adj \V {y} + \g_{\Ss {DS}} \V {1} \NR
   \NC \MC - \M {P}^\Adj \M {P} \V {g}' \leq - \M {P}^\Adj \V {y} + \g_{\Ss {DS}} \V {1} \NR
\stopcases \NR
}
\I Output \m {\Hat {\M {H}} \LA \M {K} \Rm {vec}^{-1} \SB {\Hat {g}} \M {K}^\Adj}
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Performance Metric}
{
\I We call the following quantity \m {\chi} efficiency, which is suggestive of the MIMO channel capacity.

\I Denote \m {\M {E} = \Hat {\M {H}} - \M {H}}.
\Disp {
\NC \chi
= \log \det \SB {\M {I} + \RB {\s + \F {2 \VNm {\M {E}} _2 \VNm {\M {H}} _2} {N_H ^{3/2}}} ^{-1} \M {H} \M {H} ^ \Adj} \NR
}

\I The theoretical efficiency \m {\chi _{\Rm {th}}} is defined by plugging in \m {\V {d}}.
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {\m {1/\s} vs \m {\chi}, assorted, \m {N_H=24=2N_Y}}
{
\blank [big]
\externalfigure [assorted-narrow-medium-error.png] [width=11cm]
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {\m {1/\s} vs \m {\chi}, assorted, \m {N_H=24=2N_Y}}
{
\blank [big]
\externalfigure [assorted-narrow-very-big-error.png] [width=11cm]
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {\m {1/\s} vs \m {\chi}, assorted, \m {N_H=24=3N_Y}}
{
\blank [big]
\externalfigure [assorted-wide-medium-error.png] [width=11cm]
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {\m {1/\s} vs \m {\chi}, assorted, \m {N_H=24=3N_Y}}
{
\blank [big]
\externalfigure [assorted-wide-very-big-error.png] [width=11cm]
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Time, assorted, \m {N_H=16}}
{
\blank [big]
\externalfigure [assorted-medium-time.png] [width=11cm]
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Discussion}
{
\I DS wins other method within the range drawn.

\I Simulated \m {\chi} does not show trend that estimated \m {\T {\chi}} predicts.

\I The weaker constraint on sparsity might have compromised DS's performance.

\I DS has complexity much higher than OMP, but similar to Lasso.

\I As \m {2N_H^2} grows fast, DS becomes less feasible.
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {A Successful Case of Estimation}
{
\blank [big]
\externalfigure [scatter-ddss-success.png] [wfactor=150]

\I Soft thresholding (green) correctly guesses true nonzero components (black), and refines the estimated value (orange)
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {A Failed Case of Estimation}
{
\blank [big]
\externalfigure [scatter-ddss-failure.png] [wfactor=150]

\I Soft thresholding (green) guesses wrong nonzero components (black), and the estimated value (orange) deteriorates
}
% XXX % % XXX % % XXX % % XXX % % XXX % % XXX %
\Frame {Complexity}
{
\I The number of Newton steps is about \m {\MC {O} \SB {\VNm {\V {g} _0 - \V {g} ^\star} _1}}, where \m {\VNm {\V {g} _0} _1} is the starting value, \m {\V {g} ^\star} the true value.
Assume that is \m {\MC {O} \SB {\VNm {\M {P} ^\Adj \V {z}} _1}}, or \m {\MC {O} \SB {N_H^2}}.

\I Every Newton step requires a matrix inversion of dimension \m {2 N_H^2}, with complexity \m {\MC {O} \SB {N_H^4}}, giving overall complexity \m {\MC {O} \SB {N_H^6}}.

\I Complexity of Lasso can be similarly argued to be \m {\MC {O} \SB {N_H^6}}.

\I Clearly, OMP has complexity \m {\MC {O} \SB {N_H^2}}, much smaller than DS.
}


